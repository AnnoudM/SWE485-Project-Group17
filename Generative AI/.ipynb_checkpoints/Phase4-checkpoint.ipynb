{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-cpp-python) (2.2.2)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-cpp-python) (3.1.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded to: models\\mistral-7b-instruct-v0.1.Q4_K_M.gguf\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# This will download and return the path to the file\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
    "    filename=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "    local_dir=\"models\"\n",
    ")\n",
    "\n",
    "print(\"Model downloaded to:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values After Removal:\n",
      " اسم_المدرسة                        0\n",
      "المنطقة_الإدارية                   0\n",
      "الإدارة_التعليمية                  0\n",
      "المكتب_التعليمي                    0\n",
      "السلطة                             0\n",
      "نوع_التعليم                        0\n",
      "الجنس                              0\n",
      "نوع_الاختبار                       0\n",
      "تخصص_الاختبار                      0\n",
      "متوسط_أداء_الطلبة_في_المدرسة       0\n",
      "ترتيب_المدرسة_على_مستوى_المدارس    0\n",
      "dtype: int64\n",
      "Number of rows before cleaning: 6720\n",
      "Number of rows after cleaning: 6706\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>اسم_المدرسة</th>\n",
       "      <th>المنطقة_الإدارية</th>\n",
       "      <th>الإدارة_التعليمية</th>\n",
       "      <th>المكتب_التعليمي</th>\n",
       "      <th>السلطة</th>\n",
       "      <th>نوع_التعليم</th>\n",
       "      <th>الجنس</th>\n",
       "      <th>تخصص_الاختبار</th>\n",
       "      <th>متوسط_أداء_الطلبة_في_المدرسة</th>\n",
       "      <th>ترتيب_المدرسة_على_مستوى_المدارس</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أم سلمة الثانوية للموهوبات - مقررات</td>\n",
       "      <td>مكة المكرمة</td>\n",
       "      <td>الإدارة العامة للتعليم بمنطقة مكة المكرمة</td>\n",
       "      <td>مكتب التعليم جنوب مكة المكرمة</td>\n",
       "      <td>حكومي</td>\n",
       "      <td>تعليم عام بنات</td>\n",
       "      <td>بنات</td>\n",
       "      <td>علمي</td>\n",
       "      <td>89.622377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ثانوية الرواد الأهلية ( الازدهار ) - مقررات</td>\n",
       "      <td>الرياض</td>\n",
       "      <td>الإدارة العامة للتعليم بمنطقة الرياض</td>\n",
       "      <td>شمال</td>\n",
       "      <td>أهلي</td>\n",
       "      <td>تعليم عام بنات</td>\n",
       "      <td>بنات</td>\n",
       "      <td>نظري</td>\n",
       "      <td>84.440000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ثانوية الموهوبات ( نظام مقررات )</td>\n",
       "      <td>مكة المكرمة</td>\n",
       "      <td>الإدارة العامة للتعليم بمحافظة جدة</td>\n",
       "      <td>مكتب التعليم بشمال جدة</td>\n",
       "      <td>حكومي</td>\n",
       "      <td>تعليم عام بنات</td>\n",
       "      <td>بنات</td>\n",
       "      <td>علمي</td>\n",
       "      <td>89.280423</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>الثانوية السادسة لتحفيظ القرآن الكريم 6 - مقررات</td>\n",
       "      <td>الرياض</td>\n",
       "      <td>الإدارة العامة للتعليم بمنطقة الرياض</td>\n",
       "      <td>شمال</td>\n",
       "      <td>حكومي</td>\n",
       "      <td>تحفيظ بنات</td>\n",
       "      <td>بنات</td>\n",
       "      <td>نظري</td>\n",
       "      <td>83.550000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ثانوية مدارس الظهران الاهلية (مقررات)</td>\n",
       "      <td>الشرقية</td>\n",
       "      <td>الإدارة العامة للتعليم بالمنطقة الشرقية</td>\n",
       "      <td>مكتب التعليم بمحافظة الخبر</td>\n",
       "      <td>أهلي</td>\n",
       "      <td>تعليم عام بنات</td>\n",
       "      <td>بنات</td>\n",
       "      <td>علمي</td>\n",
       "      <td>88.903225</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        اسم_المدرسة المنطقة_الإدارية  \\\n",
       "0               أم سلمة الثانوية للموهوبات - مقررات      مكة المكرمة   \n",
       "1       ثانوية الرواد الأهلية ( الازدهار ) - مقررات           الرياض   \n",
       "2                  ثانوية الموهوبات ( نظام مقررات )      مكة المكرمة   \n",
       "3  الثانوية السادسة لتحفيظ القرآن الكريم 6 - مقررات           الرياض   \n",
       "4             ثانوية مدارس الظهران الاهلية (مقررات)          الشرقية   \n",
       "\n",
       "                           الإدارة_التعليمية                المكتب_التعليمي  \\\n",
       "0  الإدارة العامة للتعليم بمنطقة مكة المكرمة  مكتب التعليم جنوب مكة المكرمة   \n",
       "1       الإدارة العامة للتعليم بمنطقة الرياض                           شمال   \n",
       "2         الإدارة العامة للتعليم بمحافظة جدة         مكتب التعليم بشمال جدة   \n",
       "3       الإدارة العامة للتعليم بمنطقة الرياض                           شمال   \n",
       "4    الإدارة العامة للتعليم بالمنطقة الشرقية     مكتب التعليم بمحافظة الخبر   \n",
       "\n",
       "  السلطة     نوع_التعليم الجنس تخصص_الاختبار  متوسط_أداء_الطلبة_في_المدرسة  \\\n",
       "0  حكومي  تعليم عام بنات  بنات          علمي                     89.622377   \n",
       "1   أهلي  تعليم عام بنات  بنات          نظري                     84.440000   \n",
       "2  حكومي  تعليم عام بنات  بنات          علمي                     89.280423   \n",
       "3  حكومي      تحفيظ بنات  بنات          نظري                     83.550000   \n",
       "4   أهلي  تعليم عام بنات  بنات          علمي                     88.903225   \n",
       "\n",
       "   ترتيب_المدرسة_على_مستوى_المدارس  \n",
       "0                                1  \n",
       "1                                1  \n",
       "2                                2  \n",
       "3                                2  \n",
       "4                                3  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Phase 4: Generative AI Integration\n",
    "# Filename: phase4_generative_ai.ipynb\n",
    "\n",
    "# ===============================\n",
    "# 📦 STEP 1: Load the dataset\n",
    "# ===============================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load cleaned dataset\n",
    "df = pd.read_csv(\"../Dataset/Averages in in General Aptitude Tests aa.csv\" )\n",
    "\n",
    "# Now we will remove all rows that have any missing values\n",
    "df_cleaned = df.dropna()  # dropna() removes any row that contains a missing value\n",
    "\n",
    "# After removing, We need to check if there are still any missing values\n",
    "print(\"Missing Values After Removal:\\n\", df_cleaned.isnull().sum())\n",
    "\n",
    "# Also, We will check the number of rows left after removing missing values\n",
    "print(f\"Number of rows before cleaning: {df.shape[0]}\")\n",
    "print(f\"Number of rows after cleaning: {df_cleaned.shape[0]}\")\n",
    "# Remove the \"نوع_الاختبار\" column as it contains only one unique value\n",
    "df_cleaned = df_cleaned.drop(columns=[\"نوع_الاختبار\"])\n",
    "\n",
    "# Check the first few rows to confirm the column is removed\n",
    "df_cleaned.head()\n",
    "# Display the top 5 rows\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from models/mistral-7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "print_info: file format = GGUF V2\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 4.07 GiB (4.83 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 3\n",
      "load: token to piece cache size = 0.1637 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.24 B\n",
      "print_info: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32000\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU\n",
      "load_tensors: layer   1 assigned to device CPU\n",
      "load_tensors: layer   2 assigned to device CPU\n",
      "load_tensors: layer   3 assigned to device CPU\n",
      "load_tensors: layer   4 assigned to device CPU\n",
      "load_tensors: layer   5 assigned to device CPU\n",
      "load_tensors: layer   6 assigned to device CPU\n",
      "load_tensors: layer   7 assigned to device CPU\n",
      "load_tensors: layer   8 assigned to device CPU\n",
      "load_tensors: layer   9 assigned to device CPU\n",
      "load_tensors: layer  10 assigned to device CPU\n",
      "load_tensors: layer  11 assigned to device CPU\n",
      "load_tensors: layer  12 assigned to device CPU\n",
      "load_tensors: layer  13 assigned to device CPU\n",
      "load_tensors: layer  14 assigned to device CPU\n",
      "load_tensors: layer  15 assigned to device CPU\n",
      "load_tensors: layer  16 assigned to device CPU\n",
      "load_tensors: layer  17 assigned to device CPU\n",
      "load_tensors: layer  18 assigned to device CPU\n",
      "load_tensors: layer  19 assigned to device CPU\n",
      "load_tensors: layer  20 assigned to device CPU\n",
      "load_tensors: layer  21 assigned to device CPU\n",
      "load_tensors: layer  22 assigned to device CPU\n",
      "load_tensors: layer  23 assigned to device CPU\n",
      "load_tensors: layer  24 assigned to device CPU\n",
      "load_tensors: layer  25 assigned to device CPU\n",
      "load_tensors: layer  26 assigned to device CPU\n",
      "load_tensors: layer  27 assigned to device CPU\n",
      "load_tensors: layer  28 assigned to device CPU\n",
      "load_tensors: layer  29 assigned to device CPU\n",
      "load_tensors: layer  30 assigned to device CPU\n",
      "load_tensors: layer  31 assigned to device CPU\n",
      "load_tensors: layer  32 assigned to device CPU\n",
      "load_tensors: tensor 'token_embd.weight' (q4_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =  4165.37 MiB\n",
      ".................................................................................................\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 2048\n",
      "llama_init_from_model: n_ctx_per_seq = 2048\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 10000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (2048) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 2048, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
      "llama_init_from_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_init_from_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_init_from_model:        CPU compute buffer size =   164.01 MiB\n",
      "llama_init_from_model: graph nodes  = 1030\n",
      "llama_init_from_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.name': 'mistralai_mistral-7b-instruct-v0.1', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=\"models/mistral-7b-instruct-v0.1.Q4_K_M.gguf\",  \n",
    "    n_ctx=2048,\n",
    "    n_threads=4, \n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_model(prompt):\n",
    "    response = llm(\n",
    "        prompt=f\"[INST] {prompt} [/INST]\",\n",
    "        max_tokens=512,\n",
    "        temperature=0.7,\n",
    "        stop=[\"</s>\"]\n",
    "    )\n",
    "    return response[\"choices\"][0][\"text\"].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regions = df_cleaned[\"المنطقة_الإدارية\"].unique().tolist()\n",
    "authorities = df_cleaned[\"السلطة\"].unique().tolist()\n",
    "genders = df_cleaned[\"الجنس\"].unique().tolist()\n",
    "edu_types = df_cleaned[\"نوع_التعليم\"].unique().tolist()\n",
    "districts = df_cleaned[\"الإدارة_التعليمية\"].unique().tolist()\n",
    "offices = df_cleaned[\"المكتب_التعليمي\"].unique().tolist()\n",
    "\n",
    "\n",
    "\n",
    "def extract_filters(user_input):\n",
    "    filters = {}\n",
    "    \n",
    "    for region in regions:\n",
    "        if region in user_input.lower():\n",
    "            filters[\"المنطقة_الإدارية\"] = region\n",
    "    for authority in authorities:\n",
    "        if authority in user_input:\n",
    "            filters[\"السلطة\"] = authority\n",
    "    for gender in genders:\n",
    "        if gender in user_input:\n",
    "            filters[\"الجنس\"] = gender\n",
    "    for edu_type in edu_types:\n",
    "        if edu_type in user_input:\n",
    "            filters[\"نوع_التعليم\"] = edu_type\n",
    "            \n",
    "    for district in districts:\n",
    "        if district in user_input:\n",
    "            filters[\"الإدارة_التعليمية\"] = district\n",
    "    for office in offices:\n",
    "        if office in user_input:\n",
    "            filters[\"المكتب_التعليمي\"] = office\n",
    "    \n",
    "    return filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "الفلاتر المستخرجة: {'المنطقة_الإدارية': 'الرياض', 'السلطة': 'حكومي', 'الجنس': 'بنات', 'الإدارة_التعليمية': 'الإدارة العامة للتعليم بمنطقة الرياض', 'المكتب_التعليمي': 'الرياض'}\n"
     ]
    }
   ],
   "source": [
    "user_input = \"طالبة تسكن في منطقة الرياض، تتبع الإدارة العامة للتعليم بمنطقة الرياض، مكتب تعليم الشمال، في مدرسة حكومية للبنات، نوع التعليم هو تعليم عام، وتبحث عن مدرسة ذات أداء أكاديمي مرتفع.\"\n",
    "\n",
    "\n",
    "# استخرج القيم\n",
    "filters = extract_filters(user_input)\n",
    "print(\"الفلاتر المستخرجة:\", filters)\n",
    "\n",
    "# فلترة الداتا\n",
    "filtered_df = df_cleaned.copy()\n",
    "for col, value in filters.items():\n",
    "    filtered_df = filtered_df[filtered_df[col] == value]\n",
    "\n",
    "top_schools = filtered_df.sort_values(by=\"ترتيب_المدرسة_على_مستوى_المدارس\", ascending=True).head(5)\n",
    "\n",
    "school_info = top_schools[\n",
    "    [\"اسم_المدرسة\", \"المنطقة_الإدارية\", \"نوع_التعليم\", \"ترتيب_المدرسة_على_مستوى_المدارس\"]\n",
    "].to_dict(orient=\"records\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_1(user_input, schools):\n",
    "    prompt = f\"📝 وصف الطالبة:\\n{user_input}\\n\\n\"\n",
    "    prompt += \"🏫 قائمة المدارس المرشحة:\\n\"\n",
    "    \n",
    "    for i, school in enumerate(schools, 1):\n",
    "        prompt += (\n",
    "            f\"{i}. اسم المدرسة: {school['اسم_المدرسة']}\\n\"\n",
    "            f\"   المنطقة: {school['المنطقة_الإدارية']}\\n\"\n",
    "            f\"   نوع التعليم: {school['نوع_التعليم']}\\n\"\n",
    "            f\"   ترتيب المدرسة: {school['ترتيب_المدرسة_على_مستوى_المدارس']}\\n\\n\"\n",
    "        )\n",
    "    \n",
    "    prompt += (\n",
    "        \"📌 اختر المدرسة صاحبة الترتيب الأعلى (أي الأصغر رقمًا) ووضح لماذا هي الأنسب للطالبة.\\n\"\n",
    "        \"📍 اذكر اسم المدرسة والسبب، باختصار وباللغة العربية فقط.\"\n",
    "    )\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 203 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  203267.91 ms\n",
      "llama_perf_context_print: prompt eval time =   16718.62 ms /   133 tokens (  125.70 ms per token,     7.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =   98156.99 ms /   328 runs   (  299.26 ms per token,     3.34 tokens per second)\n",
      "llama_perf_context_print:       total time =  115472.67 ms /   461 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEMPLATE 1 RESPONSE ===\n",
      " 📝 وصف الطالبة:\n",
      "طالبة تسكن في منطقة الرياض، تتبع الإدارة العامة للتعليم بمنطقة الرياض، مكتب تعليم الشمال، في مدرسة حكومية للبنات، نوع التعليم هو تعليم عام، وتبحث عن مدرسة ذات أداء أكاديمي مرتفع.\n",
      "\n",
      "🏫 قائمة المدارس المرشحة:\n",
      "📌 اختر المدرسة صاحبة الترتيب الأعلى (أي الأصغر رقمًا) ووضح لماذا هي الأنسب للطالبة.\n",
      "📍 اذكر اسم المدرسة والسبب، باختصار وباللغة العربية فقط.\n"
     ]
    }
   ],
   "source": [
    "# نداء LLaMA\n",
    "prompt1 = template_1(user_input, school_info)\n",
    "response_1 = ask_model(prompt1)\n",
    "print(\"=== TEMPLATE 1 RESPONSE ===\\n\", response_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
